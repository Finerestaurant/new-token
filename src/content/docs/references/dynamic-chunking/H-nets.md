---
title: H-Net
description: dynamic chunking을 활용하는 계층적 순환 모델 H-Net을 소개하는 논문입니다.
authors:
  - name: Sukjun Hwang
    affiliation: Carnegie Mellon University
  - name: Brandon Wang
    affiliation: Cartesia AI
  - name: Albert Gu
    affiliation: Carnegie Mellon University, Cartesia AI
---

[Dynamic Chunking for End-to-End Hierarchical Sequence Modeling](https://arxiv.org/html/2507.07955v2)

## 개요

최근 언어 모델(LM)의 발전에도 불구하고, 토큰화와 같은 전처리 단계는 진정한 종단 간(end-to-end) 파운데이션 모델의 구현에 걸림돌이 되어왔다. 이 논문은 콘텐츠 및 컨텍스트에 따라 자동으로 세분화 전략을 학습하는 동적 청킹(Dynamic Chunking, DC) 메커니즘을 가능하게 하는 새로운 기술들을 소개한다. 이 기술들을 명시적인 계층적 네트워크(H-Net)에 통합함으로써, 암묵적으로 계층적인 토큰화-LM-비토큰화 파이프라인을 단일 모델로 대체할 수 있다.

H-Net은 바이트 수준에서 작동하는 단일 계층의 계층 구조를 가질 때, BPE 토큰을 사용하는 강력한 트랜스포머 언어 모델보다 우수한 성능을 보인다. 여러 단계의 계층 구조를 반복하면 추상화 수준을 다양하게 모델링하여 성능이 더욱 향상되며, 데이터 스케일링에서 훨씬 더 나은 성능을 보여 두 배 크기의 토큰 기반 트랜스포머와 동등한 성능을 달성한다. 영어로 사전 학습된 H-Net은 문자 수준의 견고성을 크게 향상시키며, 어떠한 휴리스틱이나 명시적인 감독 없이도 의미 있는 데이터 의존적 청킹 전략을 학습한다. 또한, 중국어, 코드, DNA 시퀀스와 같이 토큰화 휴리스틱이 약한 언어 및 양식에서 H-Net의 개선 효과는 더욱 두드러진다.

## 핵심 키워드

*   **동적 청킹 (Dynamic Chunking, DC):** 콘텐츠 및 컨텍스트에 따라 자동으로 세분화 전략을 학습하는 메커니즘.
*   **계층적 네트워크 (Hierarchical Network, H-Net):** 동적 청킹 메커니즘을 통합하여 토큰화-LM-비토큰화 파이프라인을 대체하는 종단 간 모델.
*   **종단 간 계층적 시퀀스 모델링 (End-to-End Hierarchical Sequence Modeling):** 전처리 단계 없이 원시 데이터로부터 직접 학습하고 추상화를 구축하는 모델링 방식.
*   **토큰화 (Tokenization):** 원시 텍스트를 BPE(Byte-Pair Encoding)와 같은 알고리즘을 통해 미리 정의된 청크로 압축하는 과정.
*   **라우팅 모듈 (Routing Module):** 인접한 표현 간의 유사성을 측정하여 청크 경계를 예측하는 모듈.
*   **스무딩 모듈 (Smoothing Module):** 이산적인 청킹 작업을 미분 가능한 계산으로 변환하여 경계 학습을 용이하게 하고, 불확실한 경계의 영향을 완화하는 모듈.
*   **비율 손실 (Ratio Loss):** 모델이 너무 많은 벡터를 유지하거나 과도하게 압축하는 것을 방지하고, 원하는 압축 비율로 수렴하도록 유도하는 손실 함수.
*   **Mamba-2 레이어 (Mamba-2 layers):** H-Net의 인코더 및 디코더 네트워크에 사용되는 상태 공간 모델(SSM) 기반 레이어로, 미세한 데이터 처리 및 압축에 효율적이다.

## 시사점

H-Net은 토큰화라는 고정된 전처리 단계를 제거함으로써 딥러닝의 본질적인 목표인 원시 데이터로부터 의미 있는 패턴을 학습하고 추상화를 구축하는 데 한 걸음 더 나아갔다. 이는 언어 모델의 성능을 향상시킬 뿐만 아니라, 다음과 같은 중요한 시사점을 제공한다.

*   **진정한 종단 간 모델의 가능성:** H-Net은 토큰화 없이도 기존 토큰 기반 모델과 동등하거나 그 이상의 성능을 보여주며, 진정한 종단 간 파운데이션 모델의 개발 가능성을 제시한다. 이는 모델이 데이터로부터 직접 추상화를 학습하게 하여, 수작업으로 설계된 휴리스틱의 한계를 극복할 수 있게 한다.
*   **다국어 및 다양한 양식에서의 성능 향상:** 토큰화 휴리스틱이 약한 중국어, 코드, DNA 시퀀스와 같은 언어 및 양식에서 H-Net의 성능 개선이 더욱 두드러진다는 점은, 범용적인 모델이 다양한 데이터에 더 잘 적용될 수 있음을 시사한다.
*   **견고성 및 해석 가능성 증대:** H-Net은 텍스트 교란에 대해 훨씬 더 견고하며, 학습된 경계의 시각화를 통해 의미론적으로 일관된 단위를 자동으로 발견하는 능력을 보여준다. 이는 모델의 신뢰성과 해석 가능성을 높이는 데 기여한다.
*   **효율적인 자원 활용:** 동적 청킹을 통해 모델은 정보량이 적은 영역을 압축하고 정보량이 많은 콘텐츠를 적절한 세분성으로 보존함으로써 계산 자원을 효율적으로 할당할 수 있다.
*   **확장성 및 계층적 추상화:** H-Net의 재귀적 설계는 여러 단계의 계층 구조를 통해 더 높은 수준의 추상화를 학습할 수 있게 하며, 이는 데이터 및 파라미터 스케일링에서 더 효율적인 성능 향상을 가져온다.
