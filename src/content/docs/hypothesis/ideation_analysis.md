---
title: "Multi-Stream LM: 관련 연구 분석"
description: "Multi-Stream Language Model 아이디어의 핵심을 정의하고, 기존 연구와의 비교를 통해 독창성과 잠재적 연구 방향을 탐색합니다."
---

이 문서는 제안하는 "Multi-Stream Language Model" 아이디어를 명확히 하고, 관련 연구 동향을 심층 분석하여 아이디어를 평가하는 것을 목표로 합니다.

## 1. 핵심 아이디어 요약

제안하는 아이디어의 핵심은 기존의 단일 스트림(Single-Stream) 언어 모델의 한계를 넘어, **서로 다른 추상화 수준을 가진 여러 정보의 흐름(Stream)을 동시에 처리**하는 것입니다.

-   **주요 구성:**
    -   **'부분' 스트림 (하위 계층):** 음성 파형(waveform)이나 텍스트의 개별 토큰과 같은, 압축되지 않은 구체적이고 세밀한 정보의 흐름입니다.
    -   **'전체' 스트림 (상위 계층):** '부분' 스트림을 압축하여 본질만 남긴, '내면의 독백'이나 요약된 텍스트와 같은 추상적이고 거시적인 정보의 흐름입니다.
-   **목표:** 모델이 '전체' 맥락을 이해하면서 동시에 '부분'을 생성하거나 처리하게 함으로써, 더 유연하고 동적인 추론 및 생성 능력을 구현합니다. 이는 컴퓨터 비전 분야의 'Two-Stream' 아키텍처에서 영감을 받은 접근법입니다.

## 2. 개별 연구 상세 분석

아이디어와 관련된 연구는 크게 'Full-Duplex 상호작용'과 '계층적 표현'이라는 두 가지 그룹으로 나눌 수 있습니다.

### 2.1. Full-Duplex 상호작용 연구 그룹

이 연구들은 주로 '실시간 대화' 상황에서 발생하는 지연(latency)을 줄이고, 사용자의 끼어들기(interruption)에 자연스럽게 반응하는 것을 목표로 합니다. '동시 처리'라는 개념을 공유하지만, 초점이 다릅니다.

#### 2.1.1. Shanks: Simultaneous Hearing and Thinking

-   **논문 링크:** [Shanks: Simultaneous Hearing and Thinking for Spoken Language Models (arXiv:2510.06917v2)](https://arxiv.org/html/2510.06917v2)

    ![Shanks Architecture](/new-token/Shanks-%20Simultaneous%20Hearing%20and%20Thinking.png)

-   **아키텍처 요약:**
    -   사용자의 음성 입력을 청크(chunk) 단위로 스트리밍 처리합니다.
    -   하나의 음성 청크(Sᵢ)를 입력받으면, 이를 바탕으로 다음 음성 청크(Sᵢ₊₁)를 듣는 동안 내부적으로 '사고(thinking)' 청크(Rᵢ)를 생성합니다.
    -   '듣는 스트림'과 '사고 스트림'이라는 두 흐름을 동시적으로 운영하여, 사용자의 발화가 끝나기 전에 추론하고 끼어들기나 API 호출을 결정합니다.


-   **비교 분석: 제안 아이디어와의 관계**
    -   **공통점:** 두 개의 스트림(음성, 사고)을 동시에 처리한다는 점에서 구조적으로 유사합니다.
    -   **차이점:** Shanks의 스트림은 **기능적 분리**(입력 vs. 내부 추론)에 가깝습니다. 반면, 제안하는 아이디어의 스트림은 **동일한 내용에 대한 추상화 수준의 분리**('부분' vs. '전체')를 다룹니다. Shanks의 목표는 '상호작용의 지연 감소'인 반면, 제안 아이디어의 목표는 '이해와 추론의 깊이 향상'에 더 가깝습니다.

#### 2.1.2. Language Model Can Listen While Speaking (LSLM)

-   **논문 링크:** [Language Model Can Listen While Speaking (arXiv:2408.02622)](https://arxiv.org/abs/2408.02622)

    ![LSLM Architecture](/new-token/Language%20Model%20Can%20Listen%20While%20Speaking%20(LSLM).png)

-   **아키텍처 요약:**
    -   '말하는 채널(speaking channel)'과 '듣는 채널(listening channel)'을 동시에 통합하여 완전한 양방향(Full-Duplex) 통신을 구현합니다.
    -   모델은 자신의 이전 출력(음성 토큰)과 실시간으로 들어오는 사용자의 음성 입력을 함께 입력으로 받아 다음 토큰을 예측합니다.
    -   이를 통해 모델이 말을 하면서 동시에 사용자의 반응을 듣고, 끼어들기가 감지되면 `[IRQ]` 토큰을 통해 자신의 발화를 중단할 수 있습니다.


-   **비교 분석: 제안 아이디어와의 관계**
    -   **공통점:** 입력 스트림과 출력 스트림을 동시에 고려하는 Multi-Stream 구조입니다.
    -   **차이점:** LSLM은 '나의 출력'과 '너의 입력'이라는 **화자가 다른 두 스트림**을 다룹니다. 제안하는 아이디어는 '나의 입력' 또는 '나의 생각'을 **서로 다른 추상화 수준의 두 스트림**으로 나누어 처리한다는 점에서 근본적인 차이가 있습니다. LSLM 역시 상호작용의 동역학에 집중합니다.

#### 2.1.3. Moshi

-   **논문 링크:** [Moshi: a speech-text foundation model for real-time dialogue (arXiv:2402.19323)](https://arxiv.org/abs/2402.19323)
-   **아키텍처 요약:**
    -   실시간 양방향 대화를 위해 음성-텍스트 기반 모델(speech-text foundation model)을 제안합니다.
    -   음성을 직접 생성하는 대신, '내면의 독백'처럼 텍스트를 먼저 생성하고, 이 텍스트를 기반으로 다시 음성을 생성하는 Speech-to-Text-to-Speech 방식을 사용합니다.
    -   이를 통해 음성 스트림과 텍스트 스트림(내부 생각)을 동시에 다루는 구조를 가집니다. PersonaPlex의 기반이 된 모델입니다.
-   **비교 분석: 제안 아이디어와의 관계**
    -   **공통점:** '음성'(부분)과 '텍스트'(전체)라는, 서로 다른 추상화 수준의 정보를 다루는 다중 스트림 구조라는 점에서 제안 아이디어와 매우 유사합니다. '내면의 독백'이라는 개념은 제안 아이디어의 '전체' 스트림과 거의 일치합니다.
    -   **차이점:** Moshi의 주된 목표는 Full-Duplex 대화 시스템의 '자연스러움'과 '낮은 지연 시간'을 달성하는 것입니다. 제안하는 아이디어는 여기서 더 나아가, 이 계층적 구조를 대화뿐만 아니라 더 일반적인 '추론', '창의성', '연속 학습'의 발판으로 삼으려는 더 넓은 목표를 가집니다.

#### 2.1.4. PersonaPlex

-   **논문 링크:** [PersonaPlex: Full-Duplex Conversational AI (NVIDIA Blog)](https://developer.nvidia.com/blog/personaplex-full-duplex-conversational-ai-with-role-and-voice-control/)

    ![PersonaPlex Architecture](/new-token/presonaplex_architecture_diagram.png)

-   **아키텍처 요약:**
    -   Moshi 아키텍처를 기반으로 '동시에 듣고 말하는' 이중 스트림(dual-stream) 구성을 사용합니다.
    -   '하이브리드 프롬프팅'을 통해 텍스트 프롬프트로 역할(페르소나)을, 음성 프롬프트로 목소리 톤을 제어합니다.
    -   Full-Duplex 상호작용을 통해 자연스러운 끼어들기와 추임새를 처리하는 데 강점을 가집니다.


-   **비교 분석: 제안 아이디어와의 관계**
    -   **공통점:** Moshi 기반의 이중 스트림 구조를 활용합니다.
    -   **차이점:** PersonaPlex의 핵심 기여는 '페르소나 제어'와 'Full-Duplex 상호작용'에 있습니다. 스트림을 활용하는 방식이 LSLM과 유사하게 상호작용의 동역학을 위한 것이며, 추상화 수준을 나누어 깊은 이해를 추구하는 아이디어와는 방향이 다릅니다.

### 2.2. 계층적 표현 연구 그룹

이 연구들은 제안된 아이디어의 '계층적 표현'이라는 핵심 철학을 공유하며, 직접적인 비교 대상이 됩니다.

#### 2.2.1. Hierarchical Resolution Transformer (HRT)

-   **논문 링크:** [Hierarchical Resolution Transformers: A Wavelet-Inspired Architecture for Multi-Scale Language Understanding (arXiv:2509.20581)](https://arxiv.org/pdf/2509.20581)
-   **아키텍처 요약:**
    -   Wavelet 이론에서 영감을 받아, 단일 트랜스포머 아키텍처 내에서 **여러 해상도(resolution)의 정보를 동시에 처리**합니다.
    -   입력 시퀀스를 저해상도(coarse)와 고해상도(fine) 정보로 분리하고, 각기 다른 트랜스포머 블록에서 처리한 후 그 결과를 합치는 과정을 반복합니다.
    -   '다중 해상도 어텐션'을 통해 낮은 수준(문자)의 정보와 높은 수준(문단)의 정보를 함께 고려하여 문맥을 이해합니다.
-   **비교 분석: 제안 아이디어와의 관계**
    -   **공통점:** '부분'(고해상도)과 '전체'(저해상도)를 동시에 처리한다는 점에서 제안 아이디어의 철학과 거의 일치합니다. 이는 가장 강력한 경쟁 아이디어로 볼 수 있습니다.
    -   **차이점:** HRT는 단일 모델 내에서 영리한 어텐션 마스킹과 정보 흐름 제어를 통해 이를 구현합니다. 반면, 제안 아이디어는 Two-Stream CNN처럼 **물리적으로 분리된 두 개의 스트림**을 가정하고 시작한다는 점에서 접근법의 차이가 있습니다. 제안 아이디어는 두 스트림을 독립적으로 설계하고, 두 스트림 간의 상호작용(cross-attention 등)을 명시적으로 제어할 수 있는 잠재력을 가집니다.

#### 2.2.2. Hierarchical decoding Language model (HdLM)

-   **논문 링크:** [Making Language Model a Hierarchical Classifier and Generator (arXiv:2402.13881)](https://arxiv.org/abs/2402.13881)
-   **아키텍처 요약:**
    -   단일 언어 모델의 **레이어별로 다른 추상화 수준**을 다루도록 설계되었습니다.
    -   모델의 초기 레이어(shallow layers)는 '거친(coarse-grained)' 수준의 텍스트(예: 문단의 핵심 주제)를 생성/분류하도록 학습됩니다.
    -   후기 레이어(deep layers)는 초기 레이어의 출력을 받아 이를 점차 '세밀한(fine-grained)' 텍스트(구체적인 문장)로 다듬어 나갑니다.
-   **비교 분석: 제안 아이디어와의 관계**
    -   **공통점:** '부분'과 '전체'라는 계층적 구조를 활용합니다.
    -   **차이점:** HdLM은 **순차적인(sequential) Coarse-to-Fine** 처리 방식입니다. '전체'를 먼저 생성하고, 이를 바탕으로 '부분'을 생성합니다. 반면 제안 아이디어의 핵심은 두 스트림을 **'동시에(simultaneously)'** 처리하여 상호 영향을 주게 한다는 점에서 결정적인 차이가 있습니다.

## 3. 아키텍처 비교 분석

제안하는 아이디어와 주요 관련 연구들의 핵심 요소를 테이블로 비교하면 다음과 같습니다.

| 구분 | **제안 아이디어 (Multi-Stream LM)** | **Moshi** | **Shanks / LSLM** | **HRT** | **HdLM** |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **처리 방식** | 다중 스트림 (Multi-Stream) | 다중 스트림 (Multi-Stream) | 다중 스트림 (Multi-Stream) | 다중 해상도 (Multi-Resolution) | 단일 스트림 (Single-Stream) |
| **스트림 목적** | **계층적 표현**<br>('부분' vs '전체') | **계층적/기능적 혼합**<br>(음성 vs 텍스트) | **기능적 분리**<br>(입력 vs 사고/출력) | **계층적 표현**<br>(다중 해상도) | **계층적 표현**<br>(Coarse-to-Fine) |
| **처리 동시성** | **동시적 (Simultaneous)** | **동시적 (Simultaneous)** | **동시적 (Simultaneous)** | **동시적 (Simultaneous)** | **순차적 (Sequential)** |
| **핵심 목표** | 내용 이해/표현 | 상호작용/내용이해 | 상호작용/지연 감소 | 내용 이해/표현 | 내용 이해/표현 |
| **구현 방식** | **분리된 스트림** 가정 | **분리된 스트림** | 분리된 채널/스트림 | **단일 모델** 내 구현 | **단일 모델** 내 구현 |

## 4. 결론 및 연구 방향

위 비교 테이블을 통해 제안 아이디어의 독창성과 위치를 더 명확히 파악할 수 있습니다.

-   **독창성:** 제안 아이디어는 **'계층적 표현'**을 다루면서도(Moshi, HRT, HdLM처럼), 이를 **'명시적으로 분리된 스트림'**과 **'동시적'**으로 처리한다는(Shanks, LSLM, Moshi처럼) 점에서 기존 연구들의 특징을 독특하게 조합한 형태입니다. 특히, 가장 유사한 목표를 가진 HRT가 단일 모델 내에서 이를 구현하는 반면, Two-Stream 접근법을 차용하여 스트림 간의 상호작용을 직접 설계하려는 시도는 차별화된 지점입니다.
-   **높은 잠재력:** 관련 연구들이 기존 트랜스포머의 한계를 극복하고 뚜렷한 성능 향상을 보고하고 있어, 이 방향의 연구는 잠재력이 매우 높습니다.
-   **핵심 연구 질문:**
    1.  **차별점 증명:** 제안하는 '명시적 Multi-Stream' 아키텍처가 가장 유사한 HRT에 비해 어떤 장점을 가지는지(예: 특정 과제에서의 성능, 제어 가능성, 학습 효율성)를 명확히 입증해야 합니다.
    2.  **'압축' 메커니즘 설계:** '부분' 스트림에서 '전체' 스트림을 생성하는 '압축' 과정을 어떻게 구현할 것인지가 아키텍처의 핵심이 될 것입니다.
    3.  **벤치마크 설계:** '전체' 맥락과 '부분' 디테일을 동시에 고려해야만 풀 수 있는 새로운 태스크를 발굴하거나 설계하여, 제안 아키텍처의 장점을 극대화하여 보여줄 필요가 있습니다.

결론적으로, 제안하는 아이디어는 활발히 연구되는 두 분야의 장점을 결합한 독창적인 접근법이며, 기존 연구와의 명확한 비교 우위를 증명하는 데 연구의 초점을 맞춘다면 충분히 가치 있는 탐구가 될 것입니다.
