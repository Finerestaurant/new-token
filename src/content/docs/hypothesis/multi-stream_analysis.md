---
title: Multi-Stream 아키텍처 분석
description: Multi-Stream 아키텍처가 왜 중요한지, 관련 연구는 무엇이며 Multi-Modal과의 개념적 차이는 무엇인지 탐구합니다.
---

`1_research_plan.md`에서 언급된 압축(Compression)과 계층(Hierarchy)의 개념은 `moshi_analysis.md`에서 분석한 '내면의 독백'과 같은 계층적 예측 모델의 핵심 원리와 연결됩니다. 이 문서에서는 이러한 아이디어를 확장하여 Multi-Stream 아키텍처에 주목하는 이유를 명확히 하고, 관련 연구 및 유사 개념과의 차이점을 분석합니다.

### 1. 왜 Multi-Stream에 주목하는가: 전체와 부분의 동시적 사고

우리가 가설에서 주목하는 핵심은 **'압축'이 자연스럽게 '전체'와 '부분'이라는 계층을 형성한다**는 점입니다.
- **부분 (하위 계층):** 압축되지 않은, 세밀하고 구체적인 정보의 흐름입니다. (예: 음성의 raw waveform)
- **전체 (상위 계층):** 압축을 통해 본질만 남은, 추상적이고 거시적인 정보의 흐름입니다. (예: Moshi의 '내면의 독백'인 텍스트 토큰)

기존의 단일 파이프라인은 이러한 '부분'에서 '전체'를 순차적으로 만들어가거나, 그 반대의 과정만을 따랐습니다. 하지만 **Multi-Stream 아키텍처**는 여러 역할을 가진 정보의 흐름(Stream)을 동시에 처리함으로써, 모델이 **전체(맥락)를 생각하면서 동시에 부분(세부)을 생성**하거나 처리할 수 있게 만듭니다.

이는 `dynamic-adaptive-systems/1_research_plan.md`에서 언급한 Episodic Prediction, 즉 과거의 에피소드(전체)를 바탕으로 현재와 미래의 세부사항(부분)을 예측하는 인간의 능력과 유사한 메커니즘을 구현할 수 있는 잠재력을 가집니다.

### 2. Multi-Stream 관련 연구 사례

Multi-Stream 접근 방식은 단일 데이터 소스 내의 서로 다른 측면을 병렬로 처리하여 더 풍부한 이해를 달성하기 위해 다양한 분야에서 성공적으로 사용되었습니다.

- **Two-Stream Convolutional Networks for Action Recognition (CV):**
비디오에서 인간의 행동을 인식하기 위해 두 개의 스트림을 사용한 대표적인 연구입니다.
    1.  **Spatial Stream (공간 스트림):** 정지된 비디오 프레임(이미지)을 분석하여 '무엇'이 보이는지(객체, 장면)에 집중합니다. 이는 '부분' 또는 '순간'을 분석하는 것과 같습니다.
    2.  **Temporal Stream (시간 스트림):** 여러 프레임에 걸친 움직임(optical flow)을 분석하여 '어떻게' 움직이는지에 집중합니다. 이는 '전체'적인 맥락과 시간적 흐름을 분석하는 것과 같습니다.
이 두 스트림의 결과를 나중에 융합(fusion)함으로써, 모델은 특정 순간의 모습과 전체적인 움직임을 모두 고려하여 행동을 훨씬 정확하게 분류할 수 있습니다.

- **음성 처리 (Audio Processing):**
음성 분야에서도 원본 파형(raw waveform)을 처리하는 스트림과 스펙트로그램(spectrogram)과 같은 주파수 기반 특징을 처리하는 스트림을 함께 사용하여 음성의 다양한 특성을 동시에 학습하는 연구들이 있습니다.

### 3. 개념 비교: Multi-Stream vs. Multi-Modal

두 개념은 자주 혼용되지만, 목표와 초점이 다릅니다.

| 구분 | Multi-Stream (다중 스트림) | Multi-Modal (다중 양식) |
| :--- | :--- | :--- |
| **핵심 아이디어** | **'어떻게' 처리할 것인가**에 대한 **아키텍처** | **'무엇'을 처리할 것인가**에 대한 **데이터 종류** |
| **초점** | 정보 처리의 **방식**. 하나의 데이터를 여러 관점/표현으로 나누어 병렬 처리 | 서로 다른 **종류의 데이터**(예: 텍스트, 이미지)를 함께 이해하고 처리 |
| **예시** | (단일-모달) 비디오를 공간 스트림과 시간 스트림으로 나누어 처리 | (다중-모달) 이미지와 텍스트를 함께 입력받아 이미지에 대한 질문에 답변 |
| **관계** | Multi-Modal 모델을 구현하기 위해 Multi-Stream 아키텍처를 사용할 수 있음 (예: 이미지 스트림 + 텍스트 스트림) | 그 자체로 아키텍처를 의미하지는 않음. |

**핵심 요약:**
- **Multi-Modal**은 '무엇을' 다루는가에 대한 질문입니다. (예: 우리는 텍스트와 오디오를 다룬다.)
- **Multi-Stream**은 '어떻게' 다룰 것인가에 대한 답변 중 하나입니다. (예: 우리는 텍스트 스트림과 오디오 스트림을 병렬로 처리한다.)

따라서 우리가 Moshi와 같은 모델에서 영감을 받아 구상하는 것은, 오디오라는 단일 모달 내에서 추상적 예측(텍스트)과 구체적 예측(음성)을 수행하는 **Multi-Stream 아키텍처**이며, 이는 향후 텍스트, 이미지, 음성을 모두 다루는 **Multi-Modal** 시스템으로 확장될 때에도 핵심적인 아키텍처 원리로 작용할 수 있습니다.
