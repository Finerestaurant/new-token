---
title: Multi-Stream 아키텍처 분석
description: Multi-Stream 아키텍처가 왜 중요한지, 관련 연구는 무엇이며 Multi-Modal과의 개념적 차이는 무엇인지 탐구합니다.
---

`1_research_plan.md`에서 언급된 압축(Compression)과 계층(Hierarchy)의 개념은 `moshi_analysis.md`에서 분석한 '내면의 독백'과 같은 계층적 예측 모델의 핵심 원리와 연결됩니다. 이 문서에서는 이러한 아이디어를 확장하여 Multi-Stream 아키텍처에 주목하는 이유를 명확히 하고, 관련 연구 및 유사 개념과의 차이점을 분석합니다.

### 1. 왜 Multi-Stream에 주목하는가: 계층 구조 처리를 위한 실용적 접근

우리가 가설에서 주목하는 핵심은 **'압축'이 자연스럽게 '전체'와 '부분'이라는 계층을 형성한다**는 점입니다.
- **부분 (하위 계층):** 압축되지 않은, 세밀하고 구체적인 정보의 흐름입니다. (예: 음성의 raw waveform)
- **전체 (상위 계층):** 압축을 통해 본질만 남은, 추상적이고 거시적인 정보의 흐름입니다. (예: Moshi의 '내면의 독백'인 텍스트 토큰)

이러한 계층적 정보를 처리하는 데 반드시 Multi-Stream 아키텍처가 유일한 해답인 것은 아닙니다. 하지만 다른 연구들, 예를 들어 뒤에서 다룰 행동 인식(Action Recognition) 연구에서 공간 정보와 시간 정보를 별도의 스트림으로 동시에 처리하여 성공을 거둔 사례에서 영감을 얻을 수 있습니다.

이러한 접근법들은 서로 다른 관점의 정보를 병렬로 처리하는 것의 효율성을 보여줍니다. 마찬가지로, 우리의 가설이 제안하는 '전체(추상적 계층)'와 '부분(구체적 계층)'이라는 두 가지 다른 정보의 흐름을 동시에 처리하는 방식은 충분히 시도해 볼 만한 가치가 있는 실용적인 선택지입니다. 이는 모델이 **전체적인 맥락을 놓치지 않으면서 세부사항을 처리**하는, 보다 유연한 구조를 탐색하는 구체적인 구현 방안이 될 수 있습니다. Multi-Stream은 이 아이디어를 구현하기 위한 필수불가결한 요소라기보다는, 성공 사례에서 검증된 유망한 방법론 중 하나로 간주하는 것이 더 정확합니다.

### 2. Multi-Stream 관련 연구 사례

Multi-Stream 접근 방식은 단일 데이터 소스 내의 서로 다른 측면을 병렬로 처리하여 더 풍부한 이해를 달성하기 위해 다양한 분야에서 성공적으로 사용되었습니다.

- **Two-Stream Convolutional Networks for Action Recognition (CV):**
비디오에서 인간의 행동을 인식하기 위해 두 개의 스트림을 사용한 대표적인 연구입니다.
    1.  **Spatial Stream (공간 스트림):** 정지된 비디오 프레임(이미지)를 분석하여 '무엇'이 보이는지(객체, 장면)에 집중합니다. 이는 '부분' 또는 '순간'을 분석하는 것과 같습니다.
    2.  **Temporal Stream (시간 스트림):** 여러 프레임에 걸친 움직임(optical flow)을 분석하여 '어떻게' 움직이는지에 집중합니다. 이는 '전체'적인 맥락과 시간적 흐름을 분석하는 것과 같습니다.
이 두 스트림의 결과를 나중에 융합(fusion)함으로써, 모델은 특정 순간의 모습과 전체적인 움직임을 모두 고려하여 행동을 훨씬 정확하게 분류할 수 있습니다.

- **음성 처리 (Audio Processing):**
음성 분야에서도 원본 파형(raw waveform)을 처리하는 스트림과 스펙트로그램(spectrogram)과 같은 주파수 기반 특징을 처리하는 스트림을 함께 사용하여 음성의 다양한 특성을 동시에 학습하는 연구들이 있습니다.

### 3. 개념 비교: Multi-Stream vs. Multi-Modal

두 개념은 자주 혼용되지만, 목표와 초점이 다릅니다.

| 구분 | Multi-Stream (다중 스트림) | Multi-Modal (다중 양식) |
| :--- | :--- | :--- |
| **핵심 아이디어** | **'어떻게' 처리할 것인가**에 대한 **아키텍처** | **'무엇'을 처리할 것인가**에 대한 **데이터 종류** |
| **초점** | 정보 처리의 **방식**. 하나의 데이터를 여러 관점/표현으로 나누어 병렬 처리 | 서로 다른 **종류의 데이터**(예: 텍스트, 이미지)를 함께 이해하고 처리 |
| **예시** | (단일-모달) 비디오를 공간 스트림과 시간 스트림으로 나누어 처리 | (다중-모달) 이미지와 텍스트를 함께 입력받아 이미지에 대한 질문에 답변 |
| **관계** | Multi-Modal 모델을 구현하기 위해 Multi-Stream 아키텍처를 사용할 수 있음 (예: 이미지 스트림 + 텍스트 스트림) | 그 자체로 아키텍처를 의미하지는 않음. |

**핵심 요약:**
- **Multi-Modal**은 '무엇을' 다루는가에 대한 질문입니다. (예: 우리는 텍스트와 오디오를 다룬다.)
- **Multi-Stream**은 '어떻게' 다룰 것인가에 대한 답변 중 하나입니다. (예: 우리는 텍스트 스트림과 오디오 스트림을 병렬로 처리한다.)

따라서 우리가 Moshi와 같은 모델에서 영감을 받아 구상하는 것은, 오디오라는 단일 모달 내에서 추상적 예측(텍스트)과 구체적 예측(음성)을 수행하는 **Multi-Stream 아키텍처**이며, 이는 향후 텍스트, 이미지, 음성을 모두 다루는 **Multi-Modal** 시스템으로 확장될 때에도 핵심적인 아키텍처 원리로 작용할 수 있습니다.

### 4. 메타 분석: Multi-Stream의 잠재력과 주류가 되지 못한 이유

Multi-Stream 아키텍처는 분명 여러 측면에서 효율적이고 강력한 잠재력을 가지고 있음에도 불구하고, 왜 아직 AI 연구의 주류가 되지 못했을까?

가장 큰 이유는 지금까지의 **LLM 패러다임이 본질적으로 '턴제(Turn-based)'**였기 때문이라고 추측할 수 있다. 사용자가 입력을 마치면 모델이 응답을 생성하는 순차적 상호작용에서는, '동시에 듣고 생각하는' Multi-Stream의 진정한 효과가 두드러지게 보여질 무대가 부족했다. 즉, 실시간으로 변화하는 상황에 적응하고, 예측을 수정하며, 대화의 흐름을 유연하게 조율하는 능력을 평가받기 어려웠다.

그렇다면 Multi-Stream 아키텍처가 주목받기 위해 무엇을 증명해야 할까? 핵심은 **'상황 전체에 대한 동적인 모델링'** 능력을 보여주는 데 있다. 이는 세상을 '전체(추상적 맥락)'와 '부분(구체적 데이터)'으로 동시에 인식하고 처리하는 것을 의미한다.

이러한 관점에서 우리가 나아가야 할 방향은 다음과 같다.

1.  **'Unlearning'의 구현:** 모델이 초기에 형성한 '전체'에 대한 가설(예: 대화의 전체적인 의도)이 틀렸음을 인지했을 때, 그 가설을 동적으로 수정하고 새로운 '전체' 모델링에 기반하여 행동을 바꾸는 모습을 보여주어야 한다. 이는 단순한 정보 추가가 아닌, 기존의 잘못된 믿음을 폐기하는 **'유연성(Flexibility)'의 달성**으로 이어진다.
2.  **'창의성(Creativity)'의 발현:** '전체'와 '부분'의 상호작용 속에서, 예측하지 못한 새로운 조합이나 해결책을 제시하는 능력을 보여주는 것이다. 이는 두 스트림이 단순히 정보를 합치는 것을 넘어, 서로에게 영향을 주며 새로운 의미를 생성해낼 때 가능하다.

결론적으로, Multi-Stream 아키텍처는 단순히 정보를 병렬 처리하는 효율적인 구조를 넘어, **실시간으로 세상을 모델링하고 자신의 가설을 수정하며 유연하게 적응하는 고차원적인 지능**을 구현하는 핵심 열쇠가 될 수 있다. 이러한 가능성을 실제로 증명해낼 때, 비로소 AI 패러다임의 중요한 전환을 이끌어낼 수 있을 것이다.
