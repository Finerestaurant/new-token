---
title: "Toy Models of Superposition"
---

# 중첩의 토이 모델 (Toy Models of Superposition) 요약

이 문서는 Anthropic의 논문 "Toy Models of Superposition"의 핵심 주장, 정의, 그리고 이를 뒷받침하는 증거들을 정리한 것입니다.

## 1. 핵심 주장 (Core Thesis)

인공 신경망은 **제한된 수의 뉴런(차원)보다 더 많은 수의 특징(Features)을 표현하기 위해**, 특징들을 서로 겹쳐서(non-orthogonal) 저장하는 **'중첩(Superposition)'**이라는 전략을 사용합니다.

이로 인해 하나의 뉴런이 여러 가지 무관한 특징에 반응하는 **'다중 의미적(polysemantic)'** 현상이 발생하며, 이는 모델의 해석 가능성(Interpretability)을 어렵게 만드는 주요 원인입니다.

## 2. 주요 정의 (Key Definitions)

논문은 연구를 진행하기 위해 모호한 개념들을 다음과 같이 정의하고 전제합니다.

### 2.1. 개별 뉴런 (Individual Neuron)
*   신경망의 한 레이어를 구성하는 **활성화 값의 최소 단위** (벡터의 한 차원).
*   이상적인 상황(단일 의미성)에서는 1개의 뉴런이 1개의 특징과 매칭되어야 합니다.

### 2.2. 특징 (Feature)
*   **정의의 난해함:** 특징을 정의하는 것은 매우 어렵습니다. (임의의 함수 vs 인간이 이해 가능한 속성)
*   **실용적 정의:** **"만약 모델이 무한히 크다면, 별도의 전용 뉴런 하나를 할당해서 표현했을 입력의 속성"**으로 정의합니다.
*   **성질:**
    1.  **분해 가능성 (Decomposability):** 특징은 셀 수 있는(Countable) 독립적인 단위입니다.
    2.  **선형성 (Linearity):** 특징은 뉴런 공간(Activation Space) 상에서 특정 **방향(Direction)**을 가진 벡터로 저장됩니다.

### 2.3. 중첩 (Superposition)
*   **상황:** 표현해야 할 특징의 개수($N$)가 가용한 뉴런의 개수($M$)보다 훨씬 많을 때 ($N \gg M$).
*   **전략:** 특징 벡터들을 **직교(90도)하지 않게 배치**하여(Non-orthogonal), 약간의 **간섭(Interference)**을 허용하는 대신 더 많은 정보를 구겨 넣는 압축 전략입니다.
*   **조건:** 입력 데이터가 **희소(Sparse)**할 때(대부분 0이고 드물게 활성화될 때) 효과적으로 작동합니다.

## 3. 토이 모델을 통한 5가지 증거 (Evidence)

논문은 'ReLU 출력 모델(ReLU Output Model)'이라는 단순화된 오토인코더 구조를 사용하여 다음 현상들을 실증했습니다.

### 증거 1: 차원 수보다 많은 특징의 복원 (Overcomplete Recovery)
*   20차원 은닉층에 100개의 특징을 학습시켰을 때, 희소성이 높다면 20개 이상의 특징을 성공적으로 저장하고 복원해냄을 확인했습니다.
*   이는 모델이 실제로 중첩을 사용한다는 가장 기본적인 증거입니다.

### 증거 2: 기하학적 구조의 발견 (Geometry)
*   특징들이 은닉층 공간에서 무작위로 배치되는 것이 아니라, **간섭을 최소화하기 위한 정교한 기하학적 구조(Polytopes)**를 형성합니다.
    *   예: 2차원에 3개 특징 → 정삼각형 (벤츠 로고), 5개 특징 → 정오각형
*   이는 모델이 **톰슨 문제(Thomson Problem)**와 유사하게 "서로 밀어내는 힘(반발력)"의 균형점을 찾아 최적의 배치를 계산해냄을 의미합니다.

### 증거 3: 상전이 (Phase Change)
*   특징의 중요도나 희소성을 변화시킬 때, 모델의 행동이 점진적이 아니라 **계단식으로 급격하게 변하는(Snap)** 현상이 발견되었습니다.
*   (학습 안 함) $\leftrightarrow$ (중첩 상태) $\leftrightarrow$ (전용 뉴런 할당) 사이의 전이가 뚜렷한 물리적 상태 변화처럼 일어납니다.

### 증거 4: 다중 의미적 뉴런(Polysemantic Neurons)의 재현
*   은닉층에 특권 기저(Privileged Basis)를 부여했을 때, 실제 거대 모델에서 관찰되는 것과 동일하게 **하나의 뉴런이 여러 무관한 특징에 반응하는 현상**이 자연스럽게 발생했습니다.

### 증거 5: 중첩 상태에서의 연산 (Computation in Superposition)
*   모델은 정보를 압축해서 저장만 하는 것이 아니라, **중첩된 상태 그대로 연산(예: `abs(x)`)을 수행**할 수 있음을 증명했습니다.
*   이는 '비대칭 중첩(Asymmetric Superposition)'이라는 독특한 구조를 통해 가능했습니다.

## 4. 방향과 직교성에 대한 오해와 진실

*   **특징은 방향인가?**: 네, 기존 연구(Word2Vec, GAN 등)와 선형 접근성(Linear Accessibility) 효율 때문에 특징은 벡터 공간의 **방향(Direction)**으로 간주됩니다.
*   **특징들은 직교하는가?**:
    *   이상적인 상황(뉴런 $\ge$ 특징)에서는 **직교(Orthogonal, 90도)**합니다.
    *   중첩 상황(뉴런 $<$ 특징)에서는 **직교하지 않습니다(Non-orthogonal).** 각도를 좁혀서 빽빽하게 배치합니다.
    *   하지만 고차원 공간의 성질(존슨-린덴슈트라우스 정리) 덕분에, **"거의 직교(Almost Orthogonal)"**한 상태를 유지하여 간섭을 최소화합니다.
    *   발생하는 미세한 간섭(노이즈)은 **ReLU 활성화 함수**가 걸러냅니다.

---

## 다음 단계 (Next Steps)

*   **언어 모델(LLM)과 중첩:** 실제 대규모 언어 모델(Transformer) 환경에서는 이러한 중첩 연구가 어떻게 확장되고 진행되어 왔는지 확인합니다.
